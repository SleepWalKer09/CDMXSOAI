{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Cuarto Workshop\n",
    "\n",
    "Para revisar el workshop anterior lo puedes hacer [aqui](http://bit.ly/2quuH4c)\n",
    "\n",
    "### Pytho3(Parte 3)\n",
    "\n",
    "#### Manipulacion de listas\n",
    "\n",
    "En Python al igual que podemos crear listas, tambien las podemos manipular ya sea insertando, quitando, encontrando, contando, ordenando y revirtiendo el contenido de las mismas. Recordemos que a diferencia de los tupples, las listas son mutables. Un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# una lista de ejemplo\n",
    "x = [1,6,3,2,6,1,2,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append para insertar datos al final de la lista\n",
    "x.append(55)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que al igual que en un documento, la funcion append() inserta contenido al final del texto previo. Que tal si queremos insertar en un lugar especifico?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.insert(2,33)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver insertamos el numero 33 en el lugar 2(tercer lugar dado que se cuenta desde 0). Ahora vamos a usar remove() para quitar datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.remove(6)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver hemos eliminado el numero 6 de la lista, si quermos eliminar un digito que no existe en la lista nos marcara el siguiente error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.remove(120)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos eliminar via el indice o 'lugar' que un objeto ocupa en la lista podemos usar del:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x[7]\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para referencias un objeto via el indice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.index(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver se imprime el indice del numero 1 en este caso 0 pero de igual manera tenemos otro 1 en la lista, en casos como estos vale la pena contar cuantos numero 1 tenemos en nustra lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.count(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos ordenar una lista podemos hacer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sort()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.reverse()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera lo podemos lograr asi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.sort(reverse=False)\n",
    "print(x)\n",
    "x.sort(reverse=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listas multidimensionales\n",
    "\n",
    "Las listas multidimensionales son basicamente listas dentro de listas, rara vez encontraras en el mundo real un script que haga uso de ellas, los diccionarios son una mejor opcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[2,6],[6,2],[8,2],[5,12]]\n",
    "print(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a imprimir el segundo elemento dentro de la tercera lista\n",
    "print(x[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En caso de que quieras hacer uso de listas multidimensionales es mejor presentarlas de este modo\n",
    "y = [[5,2],\n",
    "     [6,2],\n",
    "     [3,1],\n",
    "     [12,6]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leyendo un CSV\n",
    "\n",
    "Un archivo CSV(Comma Separated Value) es un tipo de archivo muy comun cuando estamos trabajando con Python, la coma se conoce como '_delimiter_'. Un par de ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo simple de como leer un csv hacia la memoria\n",
    "import csv\n",
    "\n",
    "with open('./data/ejemplo.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        print(row)\n",
    "        print(row[0])\n",
    "        print(row[0],row[1],row[2],row[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar leimos el archivo csv e iteramos e imprimios el contenido de todas sus filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ejemplo.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    dates = []\n",
    "    colors = []\n",
    "    for row in readCSV:\n",
    "        color = row[3]\n",
    "        date = row[0]\n",
    "\n",
    "        dates.append(date)\n",
    "        colors.append(color)\n",
    "\n",
    "    print(dates)\n",
    "    print(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui agregamos el contenido del archivo csv a una variable. Que podriamos hacer con un archivo csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ejemplo.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    dates = []\n",
    "    colors = []\n",
    "    for row in readCSV:\n",
    "        color = row[3]\n",
    "        date = row[0]\n",
    "\n",
    "        dates.append(date)\n",
    "        colors.append(color)\n",
    "\n",
    "    print(dates)\n",
    "    print(colors)\n",
    "\n",
    "    # recordemos las listas\n",
    "\n",
    "    whatColor = input('Escoge un color para saber la fecha:')\n",
    "    coldex = colors.index(whatColor)\n",
    "    theDate = dates[coldex]\n",
    "    print('La fecha del',whatColor,'es:',theDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manejo de errores con Try y con Except\n",
    "\n",
    "Try y Except existen para manejar errores en Python, los podemos entender como un if-else statement en donde si usamos Try el segmento de codigo se ejecutara, y el Except no. Ambas opciones se usan para el manejo de errores en nuestro codigo.\n",
    "\n",
    "Ahora que ya sabemos que tenemos esta posibilidad tenemos que aprender a manejar errores en Ptyhon. Como lo hemos visto en sesiones anteriores si no tenemos manejo de errores en nuestro script, cuando ocurre un error, este deja de correr. En el mundo real esto se debe evitar a toda costa, en especial si tu codigo ya esta en produccion. Asi que vamos con un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./data/ejemplo.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    dates = []\n",
    "    colors = []\n",
    "    for row in readCSV:\n",
    "        color = row[3]\n",
    "        date = row[0]\n",
    "\n",
    "        dates.append(date)\n",
    "        colors.append(color)\n",
    "\n",
    "    print(dates)\n",
    "    print(colors)\n",
    "    \n",
    "    try:\n",
    "        whatColor = input('Escoge un color para saber la fecha:')\n",
    "\n",
    "        if whatColor in colors:\n",
    "            coldex = colors.index(whatColor)\n",
    "            theDate = dates[coldex]\n",
    "            print('La fecha del',whatColor,'es:',theDate)\n",
    "        else:\n",
    "            print('Ese color no esta en la lista.')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diccionarios\n",
    "\n",
    "Los diccionarios son estructuras de datos en Python que son similares a matrices de asociacion. No tienen un orden en especifico y contienen claves y valores. Cada clave es unica y los valores pueden ser cualquier cosa aunque usualmente son strings, int, floats o una lista de todas las anteriores. \n",
    "\n",
    "Los diccionarios estan definidos con __{}__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicEj = {'Hugo':15,'Paco':22,'Luis':12,'Donald':17}\n",
    "print(dicEj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Que edad tiene hugo?\n",
    "print(dicEj['Hugo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertamos a una persona mas\n",
    "dicEj['Mickey'] = 14\n",
    "print(dicEj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Su cumple fue ayer\n",
    "dicEj['Mickey']=15\n",
    "print(dicEj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrimos a Mickey de la escuela\n",
    "del dicEj['Mickey']\n",
    "print(dicEj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo mismo pero ahora con color de cabello,\n",
    "# Que color de cabello tiene Hugo?\n",
    "dicEj = {'Hugo':[15,'rubio'],'Paco':[22, 'castano'],'Luis':[12,'negro'],'Donald':[17,'rojo']}\n",
    "print(dicEj['Hugo'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones generales en Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor absoluto de una variable\n",
    "Num1 = -5\n",
    "Num2 = 5\n",
    "print(abs(Num1))\n",
    "if abs(Num1) == Num2:\n",
    "    print('Cierto!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ayuda con los modulos\n",
    "import statistics\n",
    "help(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max & Min\n",
    "Lista1 = [5,2,1,6,7]\n",
    "\n",
    "masGrande = max(Lista1)\n",
    "print(masGrande)\n",
    "\n",
    "masPeque = min(Lista1)\n",
    "print(masPeque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redondeo\n",
    "x = 5.622\n",
    "x = round(x)\n",
    "print(x)\n",
    "\n",
    "y = 5.256\n",
    "y = round(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String a Integer\n",
    "intEj = '55'\n",
    "intEj = int(intEj)\n",
    "print(intEj)\n",
    "print(type(intEj))\n",
    "\n",
    "# Integer a String\n",
    "stringEj = 55\n",
    "stringEj = str(stringEj)\n",
    "print(stringEj)\n",
    "print(type(stringEj))\n",
    "\n",
    "# Integer a Float\n",
    "floatEj = 55\n",
    "floatEj = float(floatEj)\n",
    "print(floatEj)\n",
    "print(type(floatEj))\n",
    "\n",
    "# Float a Integer\n",
    "intEj = 55.0\n",
    "intEj = int(intEj)\n",
    "print(intEj)\n",
    "print(type(intEj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modulo OS\n",
    "\n",
    "El modulo OS en Python existe con el proposito de interactuar con nuestro sistema operativo, con el puedes crear, borrar, mover folders, cambiar nuestro directorio de trabajo, etc, etc. El modulo os viene con Python por default, pero no es una funcion built-in por lo que hay que importarla. Un ejemplo sencillo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "currentDir = os.getcwd()\n",
    "print(currentDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un folder\n",
    "os.mkdir('dirNuevo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar folder\n",
    "os.rename('dirNuevo','dirNuevo2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrar folder\n",
    "os.rmdir('dirNuevo2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modulo Pickle\n",
    "\n",
    "Para terminar con Python basics exploremos el modulo de Pickle, el cual viene con tu instalacion estandar de Python. A que nos referimos con pickling? Pickling es la serialización y des-serialización de objetos de Python a un flujo de bytes. Unpicking es lo opuesto. Es posible que escuche esta metodología llamada serialización, ordenación o aplanamiento en otros idiomas, pero en Python se la conoce exclusivamente como pickling. Entonces, ¿qué significa  pickling? El pickling se usa para almacenar objetos de Python, listas, diccionarios, classes y sus objetos, etc.\n",
    "\n",
    "¿Cuáles son algunos ejemplos?\n",
    "\n",
    "En general, vamos a encontrar que el pickling es más útil en el análisis de datos, donde está realizando tareas de rutina en los datos, como el preprocesamiento. Además, tiene mucho sentido cuando trabaja con tipos de datos específicos de Python, como los diccionarios.\n",
    "\n",
    "Por ejemplo, utilizamos el pickling en la serie de tutoriales NLTK para guardar nuestro algoritmo de Machine Learning entrenado. Esto es así que, cada vez que queremos usarlo, no necesitamos volver a entrenarlo constantemente, lo que lleva un tiempo.\n",
    "\n",
    "En su lugar, solo entrenamos el algoritmo una vez, lo almacenamos en una variable (un objeto), y luego lo guardamos con pickle. En el caso del módulo NLTK, generar los clasificadores cada vez tomaba 5-15 + minutos. Con pickle, tarda unos 5 segundos.\n",
    "\n",
    "Si tienemos un conjunto de datos grande, por ejemplo, y estas cargando ese conjunto de datos masivos en la memoria cada vez que ejecuta el programa, en este tipo de casos es mejor hacer uso de pickle, y luego cargar el archivo pickle, porque será mucho más rápido, de nuevo por 50 - 100x, a veces mucho más dependiendo del tamaño.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos pickle\n",
    "import pickle\n",
    "\n",
    "# creamos un diccionario para utilizar como objecto de Python\n",
    "dicEj = {1:\"6\",2:\"2\",3:\"f\"}\n",
    "\n",
    "# nombre que le daremos al .pickle que vamos a escribir\n",
    "pickle_out = open(\"dict.pickle\",\"wb\")\n",
    "# usando el .dump guardamos el diccionario en el archivo pickle\n",
    "pickle.dump(dicEj, pickle_out)\n",
    "# como cualquier archivo abierto tenemos que cerrarlo\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abrimos el archivo de pickle\n",
    "pickle_in = open(\"dict.pickle\",\"rb\")\n",
    "# con .load() lo cargamos en una variable\n",
    "dicEj = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicEj)\n",
    "print(dicEj[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como crear un ambiente virutal\n",
    "\n",
    "Primero tenemos que instalar el modulo de venv:\n",
    "\n",
    "    - sudo apt-get update\n",
    "    \n",
    "    - sudo apt-get -y upgrade\n",
    "    \n",
    "    - sudo apt-get install -y python3-pip\n",
    "    \n",
    "    - sudo apt-get install build-essential libssl-dev libffi-dev python-dev\n",
    "    \n",
    "    - sudo apt-get install -y python3-venv\n",
    "    \n",
    "Una vez instalado el modulo venv podemos crear un ambiente virtual con Python:\n",
    "\n",
    "    - python3 -m venv ejemplo_venv\n",
    "    \n",
    "Para poder hacer uso del ambiente virtual tenemos que ir al directorio en donde creamos nuestro ambiente virtual, una vez ahi para activar nuestro ambiente virutal simplemente hacemos:\n",
    "\n",
    "    - source ejemplo_vevn/bin/activate\n",
    "    \n",
    "Para dejar de usar el ambiente virutal simplemente escribimos __deactivate__ en la terminal y listo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark\n",
    "\n",
    "#### Entendiendo Spark\n",
    "\n",
    "Apache Spark es un framework open source que se desarrollado por Metei Zaharia como parte de su tesis PhD en CU Berkeley, la primera version de spark salio en 2012, en 2013 spark paso a ser parte de Apache Software via una donacion. \n",
    "\n",
    "Apache Spark es un framework muy rapido y facil de usar que nos ayuda a resolver un rango importtante de problemas complejos sin importar si tenemos datos semi-estrucuturados, estrucutrados, streaming, o para Machine Learning y Data Science. De igual modo la comunidad de Spark es una de las mas grandes que los frameworks open source tiene.\n",
    "\n",
    "#### Que es Apache Spark?\n",
    "\n",
    "Apache Spark es un motor potente, open source, de consulta y procesamiento distribuido. Nos provee la flexibilidad y extensibilidad de MapReduce pero mucho mas rapido: 100x mas rapido que Apache Hadoop cuando tenemos datos en la memoria y 10x cuando esta en disco. Apache Spark  nos permite leer, transformar y agregar datos al igual que podemos entrenar y lanzar modelos estadisticos de una manera muy facil. De igual manera tiene APIs para Java, Scala, __Python__, R y SQL. De igual manera podemos hacer aplicaciones o \"empaquetarlas\" como librerias para lanzarlas en un cluster o para hacer analytics.\n",
    "\n",
    "Apache Spark nos da un rango de librerias muy estandares para cualquiera que haya trabajado con Python y Pandas, aunque hay que mencionar que son diferentes. Spark corre en tu laptop muy facil y con la misma facilidad lo podemos lanzar a la nube.  \n",
    "\n",
    "\n",
    "   <img src='./img/Spark_ecosystem.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proceso de ejecucion\n",
    "\n",
    "Cualquier aplicacion de Spark usa un single driver process, que puede contener multiples trabajos, en el nodo _master_ que dirige el proceso de ejecucion, que igual pueden contener multiples tareas, distrubuidas a un _n_ numero de nodos _worker_. Una imagen nos dara una ejemplo grafico:\n",
    "\n",
    "<img src='./img/spark_app.png'>\n",
    "\n",
    "El driver determina el numero y composicion de las tareas dirigidar a los nudos ejecutores, basandose en la grafica generada para el trabajo especifico, vale la pena observar que cualquier nodo _worker_ puede ejecutar tareas de cualquier trabajo.\n",
    "\n",
    "Un trabajo de Spark se asocia con una cadena de dependencia de objetos en una DAG(Direct Acyclic Graph), las cuales podemos generar a traves del Spark UI. Dado esto Spark puede optimizar la programacion(el numero de tareas y trabajadores requeridos, por ejemplo) y la ejecucion de las tareas:\n",
    "\n",
    "<img src='./img/DAG.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antes de continuar\n",
    "\n",
    "Que es la computacion paralela? \n",
    "\n",
    "Una imagen habla mas que mil palabras:\n",
    "\n",
    "<img src='./img/parvsnp.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as spark\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ejemplo = sc.parallelize([('Asus', 100), ('Apple', 300), ('Acer', 150)])\n",
    "print(data_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ejemplo = sc.parallelize([('Asus', 100), ('Apple', 300), ('Acer', 150)]).collect()\n",
    "print(data_ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ejemplo[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".appName('Intro_Spark')\\\n",
    ".config('spark.some.config.option', 'some-value')\\\n",
    ".getOrCreate()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('./data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext.getOrCreate(SparkConf())\n",
    "rdd = sc.textFile('./data/cal_housing.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rdd.map(lambda line: Row(longitude=line[0],\n",
    "                             lattitude=line[1],\n",
    "                             housingMedianAge=line[2],\n",
    "                             totalRooms=line[3],\n",
    "                             totalBedRooms=line[4],\n",
    "                             population=line[5],\n",
    "                             households=line[6],\n",
    "                             medianIncome=line[7],\n",
    "                             medianHouseValue=line[8])).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('households', 'population').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "housePop = df.select(col('households')/col('population'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('housePop', col('households')/col('population'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"./data/test.data\")\n",
    "ratings = data.map(lambda l: l.split(','))\\\n",
    "    .map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 10\n",
    "numIterations = 10\n",
    "model = ALS.train(ratings, rank, numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = ratings.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = ratings.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(sc, \"target/tmp/myCollaborativeFilter\")\n",
    "sameModel = MatrixFactorizationModel.load(sc, \"target/tmp/myCollaborativeFilter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
